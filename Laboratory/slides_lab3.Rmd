---
title: "The Labyrinth of Multiple Testing: how to avoid the pitfall of false positives"
subtitle: "FDR control"
author: "Livio Finos"
highlighter: highlight.js
job: UniversitÃ  degli Studi di Padova
output:
  prettydoc::html_pretty:
    theme: leonids 
    highlight: github
    df_print: paged
    toc: true
    number_sections: true
fontsize: 11pt
geometry: margin = 1in
mode: selfcontained
hitheme: tomorrow
framework: io2012
widgets: []
---

# False Discovery Rate


Consider a set of null hypotheses $\mathcal{H}=(H_1,\ldots,H_m)$, of which an unknown number $m_0$ are true, while the remaining $m_1=m-m_0$ are false. We can summarize the number of errors made by a *multiple testing* procedure in the following table:

Assumptions | True | False | Total
------------- | ------------- | ------------- | -------------
rejected | $V$ | $U$ | $R$ 
not rejected | $m_0 - V$ | $m_1-U$ | $m-R$
total | $m_0$ | $m_1$ | $m$

We now define the *false discovery proportion* $Q$ as. 
\[
Q = \left{\begin{array}{ll} V/R & \mathrm{se,\ } R>0\\ 0 & \mathrm{se,\,} R=0 \end{array}{right.
\]
which represents the ratio of the number of type I errors to the total number of rejected hypotheses (defined as 0 if no hypotheses are rejected), i.e., the proportion of type I errors.

Previously, we had defined the *familywise error rate* as the probability of committing at least one error of the first kind, i.e. $\Pr(V>0)$. Controlling the *familywise error rate* at $\alpha$ requires.
\[
\Pr(V>0) = \Pr(Q>0) \leq \alpha
\]
We now introduce a new error rate, the *false discovery rate* (FDR), defined as $E(Q)$.
Controlling the *false discovery rate* at $\alpha$ requires.
\[
E(Q) \leq \alpha.
\]

FDR control procedures exert less stringent control than FWER control procedures (such as Bonferroni correction), which seek to control the probability of at least one I-type error,$\Pr(V>0)$ as opposed to controlling the expected value of the proportion of I-type errors $E(Q)$. 
In fact, since $0\leq Q \leq 1$, we have. 
\[
E(Q)\leq \Pr(Q>0)
\]
which implies that the control of FWER also guarantees the control of FDR.
Consequently, we can expect the procedures for checking FDR to be more powerful than the procedures for checking FWER, i.e., to reject more hypotheses. 

In practice, methods for checking FDR are particularly more powerful than methods for checking FWER in the presence of many false null hypotheses. In contrast, if all null hypotheses are true, FDR and FWER are identical. In fact, in this case we have $R = V$, so $Q$ is a
Bernoulli random variable. It follows that
\[
E(Q) = P (Q> 0)
\]
Both FDR and FWER are generalizations proper to the concept of error of type I. If there is only one hypothesis ($m = 1$), the two error rates are identical, and equal to the probability of type I error.

# Benjamini-Hochberg procedure.

Let $p_{(1)},\ldots,p_{(m)}$ be the non-decreasingly ordered p-values, i.e., $p_{(1)}leq \ldots \leq p_{(m)}$. For a given $\alpha$,the Benjamini-Hochberg procedure for checking the FDR works as follows:

* If $p_{(i)} > \frac {i\alpha}{m}$ for any $i=1,\ldots,m$, no hypothesis is rejected.
* Otherwise, let \[
k = \max\Big\{i: p_{(i)} \leq \frac {i\alpha}{m}\Big\i}
\]
* one rejects $H_i$ when $p_i \leq \tilde{\alpha}= \Large\frac {k \alpha}{m}$

Under the assumption that the p-values are either.
* independent or positively dependent

the Benjamini-Hochberg procedure checks the FDR at the $\pi_0\alpha$ level:
\[
E(Q)\leq \pi_0 \alpha \leq \alpha.
\]

```{r} 
alpha <- 0.05
pvals <- c(0.03000,0.0002, 0.05912, 0.08226, 0.00388, 0.0184, 0.03490)
m<-length(pvals)
names(pvals)<-LETTERS[1:m]
pvals
pvals.ord<-sort(pvals) # p-values sorted
pvals.ord
(1:m)[(pvals.ord <= alpha*(1:m)/m)] # indexes i
k<-max( (1:m)*(pvals.ord <= alpha*(1:m)/m) ) # k = max(indexes i)
k
alpha.adj<-(alpha*(1:m)/m)[k] # adjusted alpha level
alpha.adj
hyps.reject<-names(pvals)[pvals<=alpha.adj] # names hypothesis rejected
hyps.reject
```

Equivalently, we can consider the rejection rule:
* we reject the hypothesis $H_{(i)}$ when $\tilde{p}_{(i)} \leq \alpha$

where 
\[
\tilde{p}_{(i)} = \min_{j=i,\ldots,m}\Big(p_{(j)}\cdot\frac{m}{j} ,1\Big)
\]

```{r} 
pvals.ord.adj<-pvals.ord * m/(1:m)
for (i in 1:m){
pvals.ord.adj[i]<-min(pvals.ord.adj[i:m],1)
}
pvals.ord.adj # adjusted p-values
pvals.ord.adj[names(pvals)] # initial sorting
pvals.adj<-p.adjust(pvals,method="BH")
pvals.adj
```


Graphically we have
```{r} 
i<-(pvals.ord <= alpha*(1:m)/m)
plot(1:m, pvals.ord, xlab="i", ylab=expression(p[(i)]), col=i+1)
segments(x0=1,y0=alpha/m, x1=m,y1=alpha)
abline(h=alpha.adj, lty="dotted")
```

For comparison, if we use Bonferroni's method we reject
```{r} 
hyps.reject.Bonf<-names(pvals)[pvals<=alpha/m]
hyps.reject.Bonf
```


# Exercise

Using the same setting (and code) as the simulation under $H_0$ partial with `r m` endpoint (last simulation of the previous laboratory) evaluate:

> The empirical distribution of the number of rejections using the correction of Bonferroni, Holm (as in the previous laboratory) and BJ
> the fraction of experiments in which at least one error was committed

```{r}
m=18
B=1000


simulazione.1.esperimento <- function(){
   # genero la risposta di 6 pazienti su m enpoint
   endpoints=matrix(rnorm(6*m),6,m)
   # aggiunto un valore di 3 ai valori riferiti 
   # ai primi 5 endpoint per i tre pazienti con il farmaco new 
   endpoints[4:6,1:5]= endpoints[4:6,1:5]+5
   endpoints
  
   p.values.1.experiment=apply(endpoints , 2, function(y) t.test(y[1:3],y[4:6])$p.value)
   
   p.bonf <- p.adjust(p.values.1.experiment,method = "bonferroni")
   p.holm <- p.adjust(p.values.1.experiment,method = "holm")
   p.bh <- p.adjust(p.values.1.experiment,method = "BH")
   
   c(bonf=calcola.err.pow(p.bonf),
     holm=calcola.err.pow(p.holm),
     bh=calcola.err.pow(p.bh))
  }

#### calcola errori e pontenza per una procedura
calcola.err.pow <- function(p.values){
  c(Almeno1errore=any(p.values[-(1:5)]<alpha),
     fdp=sum(p.values[-(1:5)]<alpha)/max(1,sum(p.values<alpha)),
     power=sum(p.values[(1:5)]<alpha)/5)
}

res <- replicate(B,simulazione.1.esperimento())
dim(res)

res[1:2,1:20]

rowMeans(res)

boxplot(res[8,])

out=matrix(rowMeans(res),3,3)
colnames(out)=c("bonf","holm","bh")
rownames(out)=c("FWER","FDR","POWER")
out
```




