---
title: "The Labyrinth of Multiple Testing: how to avoid the pitfall of false positives"
subtitle: "Hypothesis testing"
author: "Livio Finos"
highlighter: highlight.js
job: UniversitÃ  degli Studi di Padova
output:
  prettydoc::html_pretty:
    theme: leonids 
    highlight: github
    df_print: paged
    toc: true
    number_sections: true
fontsize: 11pt
geometry: margin = 1in
mode: selfcontained
hitheme: tomorrow
framework: io2012
widgets: []
---


```{r setting,echo=FALSE}
m=10
```


In this laboratory, we will understand the concept of $H_0$, $H_1$, $\alpha$ and p-value using simulations.

# One single hypothesis

## $H_0$ true

Suppose we conducted an experiment in which a new (maximum) blood pressure-lowering drug is compared with the standard drug. The response of primary interest is.  `Y`: the (maximum) pressure. You have three subjects in each sample.

The hypothesis test of interest is the equality of the means of the two samples.


**Exercise**

> 1. Generate a 'plausible' dataset under the assumption that the two drugs are equivalent.

> 2. Now compute a statistical test (and associate p-values) to test if the two drugs are equivalent.

> 3. Did you reject $H_0: \mu_{standard}=\mu_{new}$? Are you surprised?


If you do not like the example, you can imagine a completely different example. What we are interested in is the p-value (generated under the null hypothesis).

**Possible solution**

```{r}
set.seed(17)
dati=data.frame(farmaco=c("standard","standard","standard",
                        "new","new","new"),
                pressione=rnorm(6,mean = 150,sd = 10))
dati

t.test(pressione~farmaco,data=dati)
```

Here, we suppose that the mean pressure of our patients is $\mu=150$ with dev.std $\sigma=10$.


**Exercise**

> Suppose 20 labs do the same experiment (with the new drug that is always the same as the standard drug). How many times do you expect to reject the null hypothesis (Type I error)?
> What if there were 1,000 labs?
> Check it with `R`!

**Possible solution**

```{r}
# I use the previous script, at each generation I extract the p-value with $p.value and replicate B (=20 or =1000) times
B=1000
p.values.many.experiments=replicate(B,{
  dati=data.frame(farmaco=c("standard","standard","standard",
                          "new","new","new"),
                  pressione=rnorm(6,mean = 150,sd = 10))
  t.test(pressione~farmaco,data=dati)$p.value
}
)

#count how many times the p-value<.05
sum(p.values.many.experiments<.05)
```

*The p-value under $H_0$ is a uniform random variable in 0-1: p~U(0,1)*
and thus *the probability of rejecting the null hypothesis incorrectly is equal to $\alpha$: $P(p\leq\alpha|H_0)=\alpha$*

```{r}
hist(p.values.many.experiments,col="orange")
sum(p.values.many.experiments<=.05)/B
#analogously for any other significance value:
sum(p.values.many.experiments<=.10)/B
```


## $H_1$ true

Now suppose we have the same previous setting, but in this case the drug works! 

The answer of primary interest is still `Y`: pressure (minimum). One has three subjects in each sample.

The hypothesis test of interest is the equality of the averages of the two samples.

**Exercise**

> 1. Generate a 'plausible' dataset under the assumption that the two drugs are equivalent.

> 2. Now compute a statistical test (and associate p-values) to test if the two drugs are equivalent.

> 3. Did you reject $H_0: \mu_{standard}=\mu_{new}$? Are you surprised?



**Possible solution**



```{r}
set.seed(17)
dati=data.frame(farmaco=c("standard","standard","standard",
                        "new","new","new"),
                pressione=rnorm(6,mean = c(150,150,150,150-30,150-30,150-30),sd = 10))
dati

t.test(pressione~farmaco,data=dati)
```

Here, we suppose that the mean minimum pressure of our patients is $\mu=150$ with dev.std $\sigma=10$. The drug reduces the pressure by $30$.

**Exercise**

> Check the proportion of rejections by simulation in `R`!

**Possible solution**

```{r}
# I use the previous script, at each generation I extract the p-value with $p.value and replicate B (=20 or =1000) times
B=1000
p.values.many.experiments=replicate(B,{
  dati=data.frame(farmaco=c("standard","standard","standard",
                          "new","new","new"),
                  pressione=rnorm(6,mean =  c(150,150,150,150-30,150-30,150-30),sd = 10))
  t.test(pressione~farmaco,data=dati)$p.value
}
)

#count how many times the p-value<.05
sum(p.values.many.experiments<.05)
```

*The p-value under $H_1$ is a random variable with stochastically less than a U(0,1)*
and therefore *the probability of rejecting the null hypothesis CORRECTLY is $>\alpha$: $P(p\leq\alpha|H_1)>\alpha$*

```{r}
hist(p.values.many.experiments,xlim=c(0,1),col="orange")
sum(p.values.many.experiments<=.05)/B
#analogously for any other significance value:
sum(p.values.many.experiments<=.10)/B
```

# Multiple hypotheses

Now suppose that in the same experiment (more realistically) we evaluate multiple endpoints of interest and not just maximum pressure.
For each endpoint we evaluate a hypothesis and obtain a p-value.


**Exercise**

> Simulate `r B` a clinical trial with `r m` significant endpoints (e.g. using the function `replicate()`)

> Evaluate the empirical distribution of the **number of rejections** in each trial. 

> Evaluate the fraction of experiments in which **at least one error** was made.

considering two different thresholds:

- `alpha_a=.05` 
- `alpha_b=1-(1-.05)^(1/m)=` `r 1-(1-.05)^(1/m)` (Sidak's correction)

**Possible solution**

```{r}
m=10
alpha_a=.05
alpha_b=1-(1-.05)^(1/m)
# A single experiment with m endpoints (and as many hypothesis tests and p-values).

endpoints=matrix(rnorm(6*m),6,m)

p.values.1.experiment=apply(endpoints , 2, 
                            function(y) t.test(y[1:3],y[4:6],
                                               var.equal = TRUE)$p.value)

 c(n.rifiuti_a=sum(p.values.1.experiment<alpha_a),
   n.rifiuti_b=sum(p.values.1.experiment<alpha_b))

# replicate B times
res=replicate(B,
              {
 endpoints=matrix(rnorm(6*m),6,m)
 
 p.values.1.experiment=apply(endpoints , 2, 
                             function(y) t.test(y[1:3],y[4:6],
                                                var.equal = TRUE)$p.value)
 c(n.rifiuti_a=sum(p.values.1.experiment<alpha_a),
   n.rifiuti_b=sum(p.values.1.experiment<alpha_b))
}
)

#Number of rejections:
table(res["n.rifiuti_a",])
# How many times have we made at least one mistake? (= how many times at least one rejection?)
sum(res["n.rifiuti_a",]>0)

table(res["n.rifiuti_b",])
# How many times at least one error?
sum(res["n.rifiuti_b",]>0)
```


Let us now assume that the drug affects the first 5 endpoints and not the others.

**Exercise**

> Simulate `r B` a clinical trial with `r m` significant endpoints (e.g. using the function `replicate()`)

> Evaluate the empirical distribution of the **number of rejections** in each trial. 

> Evaluate the fraction of experiments in which **at least one error** was made.

considering two different thresholds:

- `alpha_a=.05` 
- `alpha_b=1-(1-.05)^(1/m)=` `r 1-(1-.05)^(1/m)` (Sidak's correction)

**Possible solution**

```{r}
# Generate the response of 6 patients on m enpoint.
endpoints=matrix(rnorm(6*m),6,m)
 
# Added a value of 3 to the values reported 
# to the first 5 endpoints for the three patients with the drug new 

endpoints[4:6,1:5]= endpoints[4:6,1:5]+3
 
endpoints

p.values.1.experiment=apply(endpoints , 2, 
                            function(y) t.test(y[1:3],y[4:6])$p.value)

 c(n.rifiuti_a=sum(p.values.1.experiment<alpha_a),
   n.rifiuti_b=sum(p.values.1.experiment<alpha_b),
   n.rifiuti_a_H0=sum(p.values.1.experiment[-(1:5)]<alpha_a),
   n.rifiuti_b_H0=sum(p.values.1.experiment[-(1:5)]<alpha_b),
   n.rifiuti_a_H1=sum(p.values.1.experiment[1:5]<alpha_a),
   n.rifiuti_b_H1=sum(p.values.1.experiment[1:5]<alpha_b))
   

p.values.1.experiment
```

The first 5 p-values tend to have lower values than the others (I reject those hypotheses several times).


In applications to real data we obviously do NOT know which hypotheses are under $H_0$ (the two drugs are equal) and which are under $H_1$ (the new drug is better).
